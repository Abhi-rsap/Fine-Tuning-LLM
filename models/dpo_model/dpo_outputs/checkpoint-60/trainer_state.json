{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.003772457913516402,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 6.28742985586067e-05,
      "grad_norm": 4.949423313140869,
      "learning_rate": 0.0,
      "logits/chosen": 0.023867320269346237,
      "logits/rejected": -0.16987597942352295,
      "logps/chosen": -421.07647705078125,
      "logps/rejected": -302.8548583984375,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.0001257485971172134,
      "grad_norm": 4.242137432098389,
      "learning_rate": 4e-05,
      "logits/chosen": 0.19925135374069214,
      "logits/rejected": -0.30889925360679626,
      "logps/chosen": -208.45388793945312,
      "logps/rejected": -183.8234405517578,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 2
    },
    {
      "epoch": 0.0001886228956758201,
      "grad_norm": 4.660715579986572,
      "learning_rate": 8e-05,
      "logits/chosen": 0.484395831823349,
      "logits/rejected": -0.33347028493881226,
      "logps/chosen": -304.7416687011719,
      "logps/rejected": -233.73301696777344,
      "loss": 0.6918,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.005023956298828125,
      "rewards/margins": 0.002753472188487649,
      "rewards/rejected": 0.0022704838775098324,
      "step": 3
    },
    {
      "epoch": 0.0002514971942344268,
      "grad_norm": 5.577284336090088,
      "learning_rate": 0.00012,
      "logits/chosen": 0.4559363126754761,
      "logits/rejected": 0.06742224097251892,
      "logps/chosen": -405.7412109375,
      "logps/rejected": -287.8029479980469,
      "loss": 0.6831,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.03006897121667862,
      "rewards/margins": 0.020358752459287643,
      "rewards/rejected": 0.009710216894745827,
      "step": 4
    },
    {
      "epoch": 0.0003143714927930335,
      "grad_norm": 4.067091941833496,
      "learning_rate": 0.00016,
      "logits/chosen": -0.03672313317656517,
      "logits/rejected": -0.4781184792518616,
      "logps/chosen": -292.8096008300781,
      "logps/rejected": -195.75765991210938,
      "loss": 0.6958,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.03009777143597603,
      "rewards/margins": -0.004914665594696999,
      "rewards/rejected": 0.035012438893318176,
      "step": 5
    },
    {
      "epoch": 0.0003772457913516402,
      "grad_norm": 5.269554615020752,
      "learning_rate": 0.0002,
      "logits/chosen": 0.2656778395175934,
      "logits/rejected": -0.14879697561264038,
      "logps/chosen": -395.56549072265625,
      "logps/rejected": -274.173583984375,
      "loss": 0.6441,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10060977935791016,
      "rewards/margins": 0.10183639824390411,
      "rewards/rejected": -0.0012266160920262337,
      "step": 6
    },
    {
      "epoch": 0.00044012008991024695,
      "grad_norm": NaN,
      "learning_rate": 0.00019636363636363636,
      "logits/chosen": -0.44450080394744873,
      "logits/rejected": -0.24875715374946594,
      "logps/chosen": -90.64482879638672,
      "logps/rejected": -241.9086456298828,
      "loss": 0.7261,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.021824264898896217,
      "rewards/margins": -0.06205463409423828,
      "rewards/rejected": 0.08387889713048935,
      "step": 7
    },
    {
      "epoch": 0.0005029943884688536,
      "grad_norm": 4.775146007537842,
      "learning_rate": 0.00019636363636363636,
      "logits/chosen": -0.5298347473144531,
      "logits/rejected": -0.7406086921691895,
      "logps/chosen": -353.59210205078125,
      "logps/rejected": -258.298583984375,
      "loss": 0.6121,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.18985377252101898,
      "rewards/margins": 0.18648825585842133,
      "rewards/rejected": 0.0033655171282589436,
      "step": 8
    },
    {
      "epoch": 0.0005658686870274604,
      "grad_norm": 3.802686929702759,
      "learning_rate": 0.00019272727272727274,
      "logits/chosen": -0.4080195128917694,
      "logits/rejected": -0.8066912293434143,
      "logps/chosen": -130.71038818359375,
      "logps/rejected": -106.77313232421875,
      "loss": 0.6854,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.011062812991440296,
      "rewards/margins": 0.01584177277982235,
      "rewards/rejected": -0.004778957925736904,
      "step": 9
    },
    {
      "epoch": 0.000628742985586067,
      "grad_norm": 4.659224033355713,
      "learning_rate": 0.0001890909090909091,
      "logits/chosen": 0.3090440034866333,
      "logits/rejected": 0.0648275762796402,
      "logps/chosen": -446.35369873046875,
      "logps/rejected": -273.9584045410156,
      "loss": 0.5892,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22466622292995453,
      "rewards/margins": 0.22984106838703156,
      "rewards/rejected": -0.005174827296286821,
      "step": 10
    },
    {
      "epoch": 0.0006916172841446738,
      "grad_norm": NaN,
      "learning_rate": 0.00018545454545454545,
      "logits/chosen": -0.08506246656179428,
      "logits/rejected": -0.7673948407173157,
      "logps/chosen": -309.5103759765625,
      "logps/rejected": -225.92990112304688,
      "loss": 0.7426,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.07027453929185867,
      "rewards/margins": -0.09410108625888824,
      "rewards/rejected": 0.02382655069231987,
      "step": 11
    },
    {
      "epoch": 0.0007544915827032804,
      "grad_norm": 5.102590084075928,
      "learning_rate": 0.00018545454545454545,
      "logits/chosen": 0.06921295076608658,
      "logits/rejected": -0.14732331037521362,
      "logps/chosen": -571.5490112304688,
      "logps/rejected": -307.0911560058594,
      "loss": 0.629,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.4499559700489044,
      "rewards/margins": 0.1592336893081665,
      "rewards/rejected": 0.2907223105430603,
      "step": 12
    },
    {
      "epoch": 0.0008173658812618872,
      "grad_norm": 6.357390880584717,
      "learning_rate": 0.00018181818181818183,
      "logits/chosen": -0.3837529122829437,
      "logits/rejected": 0.025307416915893555,
      "logps/chosen": -209.81320190429688,
      "logps/rejected": -357.90338134765625,
      "loss": 0.6969,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.10498400032520294,
      "rewards/margins": 0.01558046042919159,
      "rewards/rejected": 0.08940353989601135,
      "step": 13
    },
    {
      "epoch": 0.0008802401798204939,
      "grad_norm": 3.4347519874572754,
      "learning_rate": 0.0001781818181818182,
      "logits/chosen": 0.4144359827041626,
      "logits/rejected": 0.26621145009994507,
      "logps/chosen": -420.03985595703125,
      "logps/rejected": -292.9123840332031,
      "loss": 0.4158,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9417208433151245,
      "rewards/margins": 0.8274049758911133,
      "rewards/rejected": 0.11431579291820526,
      "step": 14
    },
    {
      "epoch": 0.0009431144783791005,
      "grad_norm": 4.379173278808594,
      "learning_rate": 0.00017454545454545454,
      "logits/chosen": 0.07217510044574738,
      "logits/rejected": -0.35038501024246216,
      "logps/chosen": -211.15138244628906,
      "logps/rejected": -266.840087890625,
      "loss": 0.5869,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.5022138953208923,
      "rewards/margins": 0.2626522183418274,
      "rewards/rejected": 0.23956166207790375,
      "step": 15
    },
    {
      "epoch": 0.0010059887769377073,
      "grad_norm": 4.299328804016113,
      "learning_rate": 0.0001709090909090909,
      "logits/chosen": 0.5213756561279297,
      "logits/rejected": 0.5486729741096497,
      "logps/chosen": -363.83050537109375,
      "logps/rejected": -423.77264404296875,
      "loss": 0.5231,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.6551498770713806,
      "rewards/margins": 0.3947492837905884,
      "rewards/rejected": 0.26040059328079224,
      "step": 16
    },
    {
      "epoch": 0.001068863075496314,
      "grad_norm": 6.59674596786499,
      "learning_rate": 0.00016727272727272728,
      "logits/chosen": 0.6543409824371338,
      "logits/rejected": 0.4646146297454834,
      "logps/chosen": -363.85992431640625,
      "logps/rejected": -355.369873046875,
      "loss": 0.7363,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.5122932195663452,
      "rewards/margins": -0.06924992054700851,
      "rewards/rejected": 0.5815432071685791,
      "step": 17
    },
    {
      "epoch": 0.0011317373740549208,
      "grad_norm": 5.132127285003662,
      "learning_rate": 0.00016363636363636366,
      "logits/chosen": -0.33600226044654846,
      "logits/rejected": -0.16091713309288025,
      "logps/chosen": -267.0841979980469,
      "logps/rejected": -482.2725830078125,
      "loss": 0.5257,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.26744765043258667,
      "rewards/margins": 0.45314082503318787,
      "rewards/rejected": -0.1856931746006012,
      "step": 18
    },
    {
      "epoch": 0.0011946116726135273,
      "grad_norm": 4.615731239318848,
      "learning_rate": 0.00016,
      "logits/chosen": -0.4120413362979889,
      "logits/rejected": -0.4390071928501129,
      "logps/chosen": -170.37680053710938,
      "logps/rejected": -183.47076416015625,
      "loss": 0.6827,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.23098096251487732,
      "rewards/margins": 0.03379387408494949,
      "rewards/rejected": 0.19718709588050842,
      "step": 19
    },
    {
      "epoch": 0.001257485971172134,
      "grad_norm": 3.663011074066162,
      "learning_rate": 0.00015636363636363637,
      "logits/chosen": -0.5964455008506775,
      "logits/rejected": -0.48590630292892456,
      "logps/chosen": -262.4664611816406,
      "logps/rejected": -456.88909912109375,
      "loss": 0.4647,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.6252387166023254,
      "rewards/margins": 0.6702048182487488,
      "rewards/rejected": -0.04496610164642334,
      "step": 20
    },
    {
      "epoch": 0.0013203602697307408,
      "grad_norm": 5.9296722412109375,
      "learning_rate": 0.00015272727272727275,
      "logits/chosen": 0.7934253215789795,
      "logits/rejected": 0.6486839652061462,
      "logps/chosen": -210.1829071044922,
      "logps/rejected": -135.6480712890625,
      "loss": 0.701,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.08134498447179794,
      "rewards/margins": 0.00700349360704422,
      "rewards/rejected": 0.07434147596359253,
      "step": 21
    },
    {
      "epoch": 0.0013832345682893476,
      "grad_norm": 4.483837604522705,
      "learning_rate": 0.0001490909090909091,
      "logits/chosen": -0.14677920937538147,
      "logits/rejected": -0.21092180907726288,
      "logps/chosen": -421.49053955078125,
      "logps/rejected": -183.37265014648438,
      "loss": 0.432,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1982702016830444,
      "rewards/margins": 1.026917815208435,
      "rewards/rejected": 0.17135238647460938,
      "step": 22
    },
    {
      "epoch": 0.0014461088668479543,
      "grad_norm": 5.745982646942139,
      "learning_rate": 0.00014545454545454546,
      "logits/chosen": 0.4941181540489197,
      "logits/rejected": 0.28870296478271484,
      "logps/chosen": -235.08985900878906,
      "logps/rejected": -206.23605346679688,
      "loss": 0.7719,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.3230898082256317,
      "rewards/margins": -0.09564820677042007,
      "rewards/rejected": -0.22744160890579224,
      "step": 23
    },
    {
      "epoch": 0.0015089831654065608,
      "grad_norm": 3.294656753540039,
      "learning_rate": 0.00014181818181818184,
      "logits/chosen": 0.5092086791992188,
      "logits/rejected": -0.061175476759672165,
      "logps/chosen": -202.98922729492188,
      "logps/rejected": -179.32574462890625,
      "loss": 0.4688,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.5906798243522644,
      "rewards/margins": 0.558712899684906,
      "rewards/rejected": 0.03196696937084198,
      "step": 24
    },
    {
      "epoch": 0.0015718574639651676,
      "grad_norm": 11.050552368164062,
      "learning_rate": 0.0001381818181818182,
      "logits/chosen": 0.394987016916275,
      "logits/rejected": -0.19399286806583405,
      "logps/chosen": -398.9195251464844,
      "logps/rejected": -156.192626953125,
      "loss": 0.9694,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.006277089938521385,
      "rewards/margins": -0.3053954839706421,
      "rewards/rejected": 0.3116725981235504,
      "step": 25
    },
    {
      "epoch": 0.0016347317625237743,
      "grad_norm": 6.0101847648620605,
      "learning_rate": 0.00013454545454545455,
      "logits/chosen": 0.21446485817432404,
      "logits/rejected": -0.2539360523223877,
      "logps/chosen": -239.0087432861328,
      "logps/rejected": -228.6139678955078,
      "loss": 0.6177,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.5313138961791992,
      "rewards/margins": 0.16688361763954163,
      "rewards/rejected": 0.3644302785396576,
      "step": 26
    },
    {
      "epoch": 0.001697606061082381,
      "grad_norm": 6.759751796722412,
      "learning_rate": 0.00013090909090909093,
      "logits/chosen": -0.39295005798339844,
      "logits/rejected": -0.6374779343605042,
      "logps/chosen": -217.66201782226562,
      "logps/rejected": -281.4107666015625,
      "loss": 0.7421,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.5334780812263489,
      "rewards/margins": -0.07112550735473633,
      "rewards/rejected": 0.6046035885810852,
      "step": 27
    },
    {
      "epoch": 0.0017604803596409878,
      "grad_norm": 6.549318790435791,
      "learning_rate": 0.00012727272727272728,
      "logits/chosen": -0.328927218914032,
      "logits/rejected": 0.3054977357387543,
      "logps/chosen": -82.92927551269531,
      "logps/rejected": -126.65782165527344,
      "loss": 0.9905,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.08008508384227753,
      "rewards/margins": -0.4960777163505554,
      "rewards/rejected": 0.5761628150939941,
      "step": 28
    },
    {
      "epoch": 0.0018233546581995946,
      "grad_norm": 3.019085168838501,
      "learning_rate": 0.00012363636363636364,
      "logits/chosen": 0.16866734623908997,
      "logits/rejected": -0.5224869251251221,
      "logps/chosen": -273.1234436035156,
      "logps/rejected": -173.61683654785156,
      "loss": 0.4457,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4539024531841278,
      "rewards/margins": 0.8059787750244141,
      "rewards/rejected": -0.35207629203796387,
      "step": 29
    },
    {
      "epoch": 0.001886228956758201,
      "grad_norm": 6.415971755981445,
      "learning_rate": 0.00012,
      "logits/chosen": 0.6360076665878296,
      "logits/rejected": 0.3609505891799927,
      "logps/chosen": -263.3526611328125,
      "logps/rejected": -255.39599609375,
      "loss": 0.7047,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.3706904947757721,
      "rewards/margins": 0.08688679337501526,
      "rewards/rejected": 0.28380370140075684,
      "step": 30
    },
    {
      "epoch": 0.0019491032553168078,
      "grad_norm": 3.2165982723236084,
      "learning_rate": 0.00011636363636363636,
      "logits/chosen": 0.6396169066429138,
      "logits/rejected": 0.33592233061790466,
      "logps/chosen": -370.34710693359375,
      "logps/rejected": -145.4835968017578,
      "loss": 0.3239,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0152254104614258,
      "rewards/margins": 1.1760749816894531,
      "rewards/rejected": -0.16084957122802734,
      "step": 31
    },
    {
      "epoch": 0.0020119775538754146,
      "grad_norm": 6.98242712020874,
      "learning_rate": 0.00011272727272727272,
      "logits/chosen": 0.09177830815315247,
      "logits/rejected": 0.22495318949222565,
      "logps/chosen": -208.7683868408203,
      "logps/rejected": -271.6256103515625,
      "loss": 0.7693,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.22603455185890198,
      "rewards/margins": -0.10786838829517365,
      "rewards/rejected": -0.11816616356372833,
      "step": 32
    },
    {
      "epoch": 0.0020748518524340213,
      "grad_norm": 5.45808219909668,
      "learning_rate": 0.00010909090909090909,
      "logits/chosen": 0.3270609974861145,
      "logits/rejected": -0.3247610330581665,
      "logps/chosen": -124.47122955322266,
      "logps/rejected": -374.432373046875,
      "loss": 0.7307,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.03122090920805931,
      "rewards/margins": -0.04463648796081543,
      "rewards/rejected": 0.07585739344358444,
      "step": 33
    },
    {
      "epoch": 0.002137726150992628,
      "grad_norm": 9.117061614990234,
      "learning_rate": 0.00010545454545454545,
      "logits/chosen": 0.21127517521381378,
      "logits/rejected": 0.01867513358592987,
      "logps/chosen": -328.29791259765625,
      "logps/rejected": -315.1631774902344,
      "loss": 0.7785,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.20384520292282104,
      "rewards/margins": -0.015067987143993378,
      "rewards/rejected": 0.21891316771507263,
      "step": 34
    },
    {
      "epoch": 0.002200600449551235,
      "grad_norm": 2.9672350883483887,
      "learning_rate": 0.00010181818181818181,
      "logits/chosen": 0.23125648498535156,
      "logits/rejected": -0.04637960344552994,
      "logps/chosen": -103.74308776855469,
      "logps/rejected": -129.26275634765625,
      "loss": 0.5513,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.44215765595436096,
      "rewards/margins": 0.3204118609428406,
      "rewards/rejected": 0.1217457726597786,
      "step": 35
    },
    {
      "epoch": 0.0022634747481098416,
      "grad_norm": 4.238447189331055,
      "learning_rate": 9.818181818181818e-05,
      "logits/chosen": -0.3561592102050781,
      "logits/rejected": 0.05511850491166115,
      "logps/chosen": -136.96243286132812,
      "logps/rejected": -206.2615203857422,
      "loss": 0.7346,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.39805868268013,
      "rewards/margins": -0.030821070075035095,
      "rewards/rejected": 0.4288797378540039,
      "step": 36
    },
    {
      "epoch": 0.0023263490466684483,
      "grad_norm": 8.126150131225586,
      "learning_rate": 9.454545454545455e-05,
      "logits/chosen": 0.955562174320221,
      "logits/rejected": 0.6685134172439575,
      "logps/chosen": -495.89654541015625,
      "logps/rejected": -307.126708984375,
      "loss": 0.73,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.38325729966163635,
      "rewards/margins": 0.008404567837715149,
      "rewards/rejected": 0.3748527765274048,
      "step": 37
    },
    {
      "epoch": 0.0023892233452270546,
      "grad_norm": 5.019591808319092,
      "learning_rate": 9.090909090909092e-05,
      "logits/chosen": 0.5046979784965515,
      "logits/rejected": 0.26877281069755554,
      "logps/chosen": -317.5967102050781,
      "logps/rejected": -151.69810485839844,
      "loss": 0.5717,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.9717637896537781,
      "rewards/margins": 0.2788495123386383,
      "rewards/rejected": 0.6929143071174622,
      "step": 38
    },
    {
      "epoch": 0.0024520976437856614,
      "grad_norm": 5.847448825836182,
      "learning_rate": 8.727272727272727e-05,
      "logits/chosen": 0.4317691922187805,
      "logits/rejected": -0.5139607787132263,
      "logps/chosen": -443.419921875,
      "logps/rejected": -301.89434814453125,
      "loss": 0.5637,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.525822639465332,
      "rewards/margins": 0.3574179410934448,
      "rewards/rejected": 0.1684047281742096,
      "step": 39
    },
    {
      "epoch": 0.002514971942344268,
      "grad_norm": 5.271589279174805,
      "learning_rate": 8.363636363636364e-05,
      "logits/chosen": -0.16243290901184082,
      "logits/rejected": -0.5020787119865417,
      "logps/chosen": -249.49481201171875,
      "logps/rejected": -413.870849609375,
      "loss": 0.6355,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.7471655011177063,
      "rewards/margins": 0.3826945424079895,
      "rewards/rejected": 0.3644709587097168,
      "step": 40
    },
    {
      "epoch": 0.002577846240902875,
      "grad_norm": 8.908154487609863,
      "learning_rate": 8e-05,
      "logits/chosen": 0.33803457021713257,
      "logits/rejected": 0.029357697814702988,
      "logps/chosen": -309.2728271484375,
      "logps/rejected": -586.4541625976562,
      "loss": 0.747,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.7407932877540588,
      "rewards/margins": 0.08196792006492615,
      "rewards/rejected": 0.6588253378868103,
      "step": 41
    },
    {
      "epoch": 0.0026407205394614816,
      "grad_norm": 7.471556186676025,
      "learning_rate": 7.636363636363637e-05,
      "logits/chosen": 0.7470524311065674,
      "logits/rejected": -0.19239592552185059,
      "logps/chosen": -457.73211669921875,
      "logps/rejected": -227.4053955078125,
      "loss": 0.6373,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.413240909576416,
      "rewards/margins": 0.15952107310295105,
      "rewards/rejected": 0.25371983647346497,
      "step": 42
    },
    {
      "epoch": 0.0027035948380200884,
      "grad_norm": 4.977187633514404,
      "learning_rate": 7.272727272727273e-05,
      "logits/chosen": 0.4041883051395416,
      "logits/rejected": 0.5489032864570618,
      "logps/chosen": -375.1722717285156,
      "logps/rejected": -252.57931518554688,
      "loss": 0.7061,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.7122411727905273,
      "rewards/margins": 0.045758821070194244,
      "rewards/rejected": 0.6664823889732361,
      "step": 43
    },
    {
      "epoch": 0.002766469136578695,
      "grad_norm": 3.384047269821167,
      "learning_rate": 6.90909090909091e-05,
      "logits/chosen": 0.7018091678619385,
      "logits/rejected": 0.6349743604660034,
      "logps/chosen": -319.6846618652344,
      "logps/rejected": -221.9697265625,
      "loss": 0.3444,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 1.0843929052352905,
      "rewards/margins": 1.2775077819824219,
      "rewards/rejected": -0.19311486184597015,
      "step": 44
    },
    {
      "epoch": 0.002829343435137302,
      "grad_norm": 4.078099250793457,
      "learning_rate": 6.545454545454546e-05,
      "logits/chosen": 0.37913405895233154,
      "logits/rejected": -0.27794986963272095,
      "logps/chosen": -303.0443115234375,
      "logps/rejected": -150.9921875,
      "loss": 0.4574,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1416282653808594,
      "rewards/margins": 0.6271424293518066,
      "rewards/rejected": 0.5144859552383423,
      "step": 45
    },
    {
      "epoch": 0.0028922177336959086,
      "grad_norm": 4.786370277404785,
      "learning_rate": 6.181818181818182e-05,
      "logits/chosen": 0.27804800868034363,
      "logits/rejected": 0.2439471185207367,
      "logps/chosen": -309.00091552734375,
      "logps/rejected": -271.11663818359375,
      "loss": 0.5589,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 1.0323823690414429,
      "rewards/margins": 0.5151879191398621,
      "rewards/rejected": 0.517194390296936,
      "step": 46
    },
    {
      "epoch": 0.0029550920322545153,
      "grad_norm": 6.799770355224609,
      "learning_rate": 5.818181818181818e-05,
      "logits/chosen": 1.076368808746338,
      "logits/rejected": 0.5227884650230408,
      "logps/chosen": -360.41986083984375,
      "logps/rejected": -295.89349365234375,
      "loss": 0.5523,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 1.2257015705108643,
      "rewards/margins": 0.6755189895629883,
      "rewards/rejected": 0.5501825213432312,
      "step": 47
    },
    {
      "epoch": 0.0030179663308131217,
      "grad_norm": 4.430849552154541,
      "learning_rate": 5.4545454545454546e-05,
      "logits/chosen": -0.07072556018829346,
      "logits/rejected": 0.2648845314979553,
      "logps/chosen": -242.9970703125,
      "logps/rejected": -173.87632751464844,
      "loss": 0.4614,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.9318521022796631,
      "rewards/margins": 0.6510701179504395,
      "rewards/rejected": 0.28078192472457886,
      "step": 48
    },
    {
      "epoch": 0.0030808406293717284,
      "grad_norm": 7.177042007446289,
      "learning_rate": 5.090909090909091e-05,
      "logits/chosen": -0.24192851781845093,
      "logits/rejected": -0.45720645785331726,
      "logps/chosen": -192.7063446044922,
      "logps/rejected": -291.7709045410156,
      "loss": 0.7902,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.2883415222167969,
      "rewards/margins": -0.15952739119529724,
      "rewards/rejected": 0.4478689432144165,
      "step": 49
    },
    {
      "epoch": 0.003143714927930335,
      "grad_norm": 11.301621437072754,
      "learning_rate": 4.7272727272727275e-05,
      "logits/chosen": 0.012289151549339294,
      "logits/rejected": 0.0007299035787582397,
      "logps/chosen": -232.48818969726562,
      "logps/rejected": -231.79840087890625,
      "loss": 0.9623,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.8267364501953125,
      "rewards/margins": -0.2551240622997284,
      "rewards/rejected": 1.0818605422973633,
      "step": 50
    },
    {
      "epoch": 0.003206589226488942,
      "grad_norm": 4.320897102355957,
      "learning_rate": 4.3636363636363636e-05,
      "logits/chosen": 0.05917230248451233,
      "logits/rejected": -0.3031436800956726,
      "logps/chosen": -144.49911499023438,
      "logps/rejected": -172.879638671875,
      "loss": 0.4653,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4405595362186432,
      "rewards/margins": 0.5582200884819031,
      "rewards/rejected": -0.1176605373620987,
      "step": 51
    },
    {
      "epoch": 0.0032694635250475486,
      "grad_norm": 5.608449459075928,
      "learning_rate": 4e-05,
      "logits/chosen": -0.19467861950397491,
      "logits/rejected": -0.1153804287314415,
      "logps/chosen": -264.36669921875,
      "logps/rejected": -309.70709228515625,
      "loss": 0.6328,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.34999504685401917,
      "rewards/margins": 0.22345122694969177,
      "rewards/rejected": 0.1265438199043274,
      "step": 52
    },
    {
      "epoch": 0.0033323378236061554,
      "grad_norm": 4.304490089416504,
      "learning_rate": 3.6363636363636364e-05,
      "logits/chosen": 0.47288206219673157,
      "logits/rejected": -0.612645149230957,
      "logps/chosen": -176.49525451660156,
      "logps/rejected": -135.56495666503906,
      "loss": 0.6865,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.291521281003952,
      "rewards/margins": 0.09861098229885101,
      "rewards/rejected": 0.19291026890277863,
      "step": 53
    },
    {
      "epoch": 0.003395212122164762,
      "grad_norm": 4.670788288116455,
      "learning_rate": 3.272727272727273e-05,
      "logits/chosen": 0.2616814076900482,
      "logits/rejected": -0.12639205157756805,
      "logps/chosen": -725.8343505859375,
      "logps/rejected": -539.62939453125,
      "loss": 0.38,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3820732831954956,
      "rewards/margins": 1.0443599224090576,
      "rewards/rejected": 0.3377132713794708,
      "step": 54
    },
    {
      "epoch": 0.003458086420723369,
      "grad_norm": 5.648433685302734,
      "learning_rate": 2.909090909090909e-05,
      "logits/chosen": -0.31010279059410095,
      "logits/rejected": -0.7317851781845093,
      "logps/chosen": -303.69403076171875,
      "logps/rejected": -317.4551086425781,
      "loss": 0.5338,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.6136019229888916,
      "rewards/margins": 0.37530001997947693,
      "rewards/rejected": 0.23830188810825348,
      "step": 55
    },
    {
      "epoch": 0.0035209607192819756,
      "grad_norm": 4.336921215057373,
      "learning_rate": 2.5454545454545454e-05,
      "logits/chosen": 0.8746156692504883,
      "logits/rejected": 0.3027946650981903,
      "logps/chosen": -313.88323974609375,
      "logps/rejected": -173.9926300048828,
      "loss": 0.5188,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.7009021639823914,
      "rewards/margins": 0.9828100204467773,
      "rewards/rejected": -0.28190794587135315,
      "step": 56
    },
    {
      "epoch": 0.0035838350178405824,
      "grad_norm": 4.792107582092285,
      "learning_rate": 2.1818181818181818e-05,
      "logits/chosen": -0.20444366335868835,
      "logits/rejected": -0.09266527742147446,
      "logps/chosen": -381.8840637207031,
      "logps/rejected": -192.91697692871094,
      "loss": 0.527,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.29057613015174866,
      "rewards/margins": 0.46309810876846313,
      "rewards/rejected": -0.17252196371555328,
      "step": 57
    },
    {
      "epoch": 0.003646709316399189,
      "grad_norm": 6.039638996124268,
      "learning_rate": 1.8181818181818182e-05,
      "logits/chosen": 0.4537574052810669,
      "logits/rejected": -0.36294957995414734,
      "logps/chosen": -332.2868957519531,
      "logps/rejected": -272.1440124511719,
      "loss": 0.6845,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.6939056515693665,
      "rewards/margins": 0.18760891258716583,
      "rewards/rejected": 0.5062967538833618,
      "step": 58
    },
    {
      "epoch": 0.0037095836149577954,
      "grad_norm": 4.5375847816467285,
      "learning_rate": 1.4545454545454545e-05,
      "logits/chosen": 0.2274899035692215,
      "logits/rejected": 0.1312253624200821,
      "logps/chosen": -307.32293701171875,
      "logps/rejected": -259.15576171875,
      "loss": 0.3818,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 1.1863888502120972,
      "rewards/margins": 1.068627953529358,
      "rewards/rejected": 0.11776101589202881,
      "step": 59
    },
    {
      "epoch": 0.003772457913516402,
      "grad_norm": 8.039170265197754,
      "learning_rate": 1.0909090909090909e-05,
      "logits/chosen": 0.7018934488296509,
      "logits/rejected": 0.7372109889984131,
      "logps/chosen": -175.74644470214844,
      "logps/rejected": -169.71849060058594,
      "loss": 1.2047,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.06663893163204193,
      "rewards/margins": -0.7273445129394531,
      "rewards/rejected": 0.7939834594726562,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
